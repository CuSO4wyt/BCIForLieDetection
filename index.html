<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="description" content="A cutting-edge research project focusing on Brain-Computer Interface-based deception detection using multimodal biosignals. Join us in advancing neuroscience and AI.">
    <meta property="og:title" content="BCI-Based Deception Detection System | Advanced Research in Neuroscience & AI" />
    <meta property="og:description" content="Explore the intersection of neuroscience, AI, and human behavior with our project on Brain-Computer Interface-based deception detection." />
    <meta property="twitter:title" content="BCI-Based Deception Detection System" />
    <meta property="twitter:description" content="Join our academic journey into the future of deception detection through BCI technologies, combining EEG, heart rate, facial expressions, and speech." />
    <meta name="keywords" content="BCI, Deception Detection, Neuroscience, AI, Multimodal Biosignals, EEG, Heart Rate, Facial Expressions, Speech" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>BCI-Based Deception Detection System</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Roboto+Slab|Merriweather&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>

    <style>
        /* Prevent navbar overlap */
        .hero {
            padding-top: 80px; /* Adjust the value based on navbar height */
        }

        /* Keep video responsive with a 16:9 aspect ratio */


        .video-container-9x16 {
            position: relative;
            width: 50%; /* Áº©Â∞èÂÆΩÂ∫¶ */
            padding-bottom: 88.89%; /* 9:16ÊØî‰æãÔºå9/16 = 0.5625, ÊâÄ‰ª•1/0.5625 = 1.7778 */
            height: 0;
            overflow: hidden;
            border-radius: 12px;
            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.2);
            margin: 0 auto;
        }

                /* Style for adding GIFs to the left and right sides */
        .gif-decor {
            position: absolute;
            top: 0;
            width: 20%; /* Adjust width as necessary */
            height: 20%;
            z-index: -1; /* Ensure the GIFs stay behind the main content */
        }
        

        .left-gif {
            left: 0;
            background-image: url('gif1.gif'); /* Replace with your actual GIF path */
            background-size: contain; /* Ensures GIF scales to fit within the element */
            width: 15%; /* Adjust to desired size */
            height: 240%;
        }
        
        .right-gif {
            right: 0;
            background-image: url('gif2.gif'); /* Replace with your actual GIF path */
            background-size: contain; /* Ensures GIF scales to fit within the element */
            width: 15%; /* Adjust to desired size */
            height: 240%;
        }

        
                

        /* Adjust navbar if necessary */
        .navbar {
            background-color: #2E3A87;
            padding: 1rem 0;
        }

        .navbar-item {
            color: #ffffff !important;
        }

        .navbar-item:hover {
            color: #f1f1f1 !important;
        }

        .publication-title {
            font-family: 'Roboto Slab', serif;
            font-weight: bold;
            color: #2E3A87;
        }

        .publication-authors {
            font-family: 'Merriweather', serif;
            font-size: 1.2em;
            color: #444;
        }

        .footer {
            background-color: #f1f1f1;
            padding: 1em 0;
        }

        .title.is-2 {
            font-family: 'Roboto Slab', serif;
            color: #2E3A87;
        }

        .content.is-medium {
            line-height: 1.8;
        }
    </style>
</head>

<body>

    <nav class="navbar is-fixed-top">
        <div class="navbar-brand">
            <a class="navbar-item" href="#">
                <h2>BCI Deception Detection</h2>
            </a>
        </div>
        <div class="navbar-menu">
            <a class="navbar-item" href="#about-us">About Us</a>
            <a class="navbar-item" href="#experiment-demo">Demo</a>
            <a class="navbar-item" href="#project-news">News</a>
            <a class="navbar-item" href="#contact-us">Contact</a>
        </div>
    </nav>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">A Brain-Computer Interface-Based Deception Detection System</h1>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- About Us Section -->
    <section class="section" id="about-us">
        <div class="container is-max-desktop">
            <h2 class="title is-2 has-text-centered">About Us üëã</h2>
            <div class="content is-medium">
                <p>
                    We are a passionate research team from <strong>Nanjing University</strong> üè´, driven by curiosity, creativity, and a shared mission to explore the frontier of brain-computer interface (BCI) technologies üß†üí°.
                </p>
                <p>
                    Our current project focuses on building a <em>multimodal deception detection system</em> that integrates physiological signals such as EEG, heart rate, facial expressions, and speech üß™üéôÔ∏è. We aim to bridge neuroscience, AI, and human behavior to create meaningful real-world applications üåçü§ñ.
                </p>
                <p>
                    Thanks for visiting our page ‚Äî stay tuned for updates, demos, and publications! üöÄüì¢
                </p>
            </div>
        </div>
    </section>

    <!-- Teaser Video Section -->
<!-- Teaser Video Section -->
<section class="hero teaser" id="experiment-demo">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <h2 class="title is-2 has-text-centered mb-6">Experiment Demo üé¨</h2>
            <div class="columns is-centered">
                <div class="column is-12">
                    <div class="columns">
                        <!-- Video container (left side) -->
                        <div class="column is-6">
                            <div class="video-container-9x16">
                                <video id="demo-video" autoplay controls muted loop width="100%" height="100%">
                                    <source src="static/videos/demo.mp4" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                        </div>
                        <!-- Description text (right side) -->
                        <div class="column is-8">
                            <div class="content is-medium">
                                <p>
                                  (1) Collect EEG, heart rate, blood oxygen, facial expression (muscle activity), and speech data.<br><br>
                                  (2) Participants speak in diverse scenarios (e.g., merit evaluations, job interviews).<br><br>
                                  (3) Standardized data forms a multimodal deception detection dataset for model training.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


    <!-- Project News Section -->
    <section class="section" id="project-news">
        <div class="container is-max-desktop">
            <h2 class="title is-2 has-text-centered">Project NewsüöÄ</h2>
            <div class="content">
                <ul>
                    <li><strong>May 4, 2025</strong> ‚Äì Final phase: Model training refinement and validation continues. Recruitment for a second round of participants is planned for external testing.</li>
            
                    <li><strong>Apr. 13, 2025</strong> ‚Äì Initial model integration and evaluation completed. Participated in the China International Student Innovation Competition and launched preliminary commercial value investigation.</li>
            
                    <li><strong>Mar. 30, 2025</strong> ‚Äì Formal experiments completed. Data collection, participant feedback, and scenario annotation finished. System optimization underway with support for downstream applications.</li>
            
                    <li><strong>Mar. 2, 2025</strong> ‚Äì Participant recruitment and scheduling completed. Detailed experimental execution plan finalized.</li>
            
                    <li><strong>Feb. 23, 2025</strong> ‚Äì Returned to campus for equipment re-testing and conducted small-scale internal experiments to refine procedures and improve participant experience.</li>
            
                    <li><strong>Feb. 16, 2025</strong> ‚Äì Literature review and study on multimodal data processing and AI modeling methods completed. Dataset structure designed and established.</li>
            
                    <li><strong>Jan. 5, 2025</strong> ‚Äì Equipment calibration and preliminary functional validation completed. Script and process adjusted after pilot testing with early participants.</li>
            
                    <li><strong>Dec. 16, 2024</strong> ‚Äì Finalized experiment plan and materials, confirmed equipment list, and completed procurement.</li>
            
                    <li><strong>Dec. 1, 2024</strong> ‚Äì Drafted the first version of the experimental protocol, including the Participant Instruction Manual and Consent Form.</li>
            
                    <li><strong>Nov. 17, 2024</strong> ‚Äì Initial technical roadmap and literature review completed. Gained foundational understanding of relevant workflows.</li>
                </ul>    
            </div>
        </div>
    </section>

            
            <!-- Left-side GIF decoration -->
        <div class="gif-decor left-gif"></div>
        
        <!-- Right-side GIF decoration -->
        <div class="gif-decor right-gif"></div>


    <!-- Footer Section -->
    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This project is a collaboration between the <strong>Nanjing University</strong> research team. 
                            For inquiries or collaboration opportunities, please <a href="mailto:contact@bci-research.com">email us</a>.
                        </p>
                        <p>
                            Built with passion and driven by curiosity in the field of Brain-Computer Interfaces and AI.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html> 
